{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework2_ImageSegmentationNBModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngooKRKWuosd"
      },
      "source": [
        "#IMPORT USEFUL LIBRARIES\r\n",
        "\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
        "\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import json\r\n",
        "import pandas as pd\r\n",
        "import math\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import skimage\r\n",
        "from skimage import transform\r\n",
        "\r\n",
        "from keras.models import Model\r\n",
        "from tensorflow.keras.layers import *\r\n",
        "from tensorflow.python.keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D, Conv2DTranspose\r\n",
        "from tensorflow.python.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKxecBSmv8EF"
      },
      "source": [
        "#SET RANDOM SEED\r\n",
        "SEED = 1234\r\n",
        "tf.random.set_seed(SEED)  \r\n",
        "cwd = os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU8yRxwnv8vf"
      },
      "source": [
        "#GOOGLE DRIVE\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vts8VSpXv8l7"
      },
      "source": [
        "#UNZIP DATASET FOLDER\r\n",
        "!unzip '/content/drive/My Drive/Development_Dataset.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPdhyhp9v8Zr"
      },
      "source": [
        "#SET IMAGE TRAINING SHAPE\r\n",
        "img_h = 512\r\n",
        "img_w = 512\r\n",
        "\r\n",
        "out_shape = [img_h, img_w]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_5l2c5awYrR"
      },
      "source": [
        "#SET DIRECTORIES\r\n",
        "\r\n",
        "dataset_dir = os.path.join(cwd, '/content/Development_Dataset/')\r\n",
        "\r\n",
        "training_dir = os.path.join(dataset_dir, 'Training/Bipbip/Mais/') #to modify each time we want to use a different training/valid set\r\n",
        "\r\n",
        "dataset_dir\r\n",
        "training_dir\r\n",
        "\r\n",
        "mask_dir =  os.path.join(dataset_dir, 'Training/Bipbip/Mais/Masks/') #to modify each time we want to use a different training/valid set\r\n",
        "mask_dir\r\n",
        "\r\n",
        "test_dir = os.path.join(dataset_dir, 'Test_Dev/')\r\n",
        "test_dir\r\n",
        "\r\n",
        "prediction_dir = os.path.join('/content/drive/My Drive', \"predictions\")\r\n",
        "if (not os.path.exists(prediction_dir)):\r\n",
        "  os.makedirs(prediction_dir)\r\n",
        "prediction_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yaZLGhywcP6"
      },
      "source": [
        "#DATA GENERATORS\r\n",
        "\r\n",
        "img_data_gen = ImageDataGenerator(rotation_range=10,\r\n",
        "                                      width_shift_range=5,\r\n",
        "                                      height_shift_range=5,\r\n",
        "                                      zoom_range=0,\r\n",
        "                                      horizontal_flip=True,\r\n",
        "                                      vertical_flip=True,\r\n",
        "                                      fill_mode='reflect')\r\n",
        "mask_data_gen = ImageDataGenerator(rotation_range=10,\r\n",
        "                                       width_shift_range=5,\r\n",
        "                                       height_shift_range=5,\r\n",
        "                                       zoom_range=0,\r\n",
        "                                       horizontal_flip=True,\r\n",
        "                                       vertical_flip=True,\r\n",
        "                                       fill_mode='reflect')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9Pl6ZVRwfPj"
      },
      "source": [
        "#FUNCTION TO CONVERT DATASET (RGB) MASKS INTO TRAINING MASKS (ONE CLASS PER PIXEL)\r\n",
        "def read_rgb_mask(mask_img):\r\n",
        "    \r\n",
        "    mask_arr = np.array(mask_img)\r\n",
        "\r\n",
        "    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\r\n",
        "\r\n",
        "    # Use RGB dictionary in 'RGBtoTarget.txt' to convert RGB to target\r\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [254, 124, 18], axis=-1))] = 0\r\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\r\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\r\n",
        "\r\n",
        "    return new_mask_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sVVrZGJwiLu"
      },
      "source": [
        "#DATA PREPROCESSING\r\n",
        "\r\n",
        "validation_split = 0.8\r\n",
        "\r\n",
        "img_arr = []\r\n",
        "mask_arr = []\r\n",
        "\r\n",
        "#DATASET ARRAY CREATION\r\n",
        "\r\n",
        "for img in os.listdir(os.path.join(training_dir, \"Images\")):\r\n",
        "  print(img)\r\n",
        "\r\n",
        "  img_path = os.path.join(training_dir, \"Images\", img)\r\n",
        "  image = Image.open(img_path)\r\n",
        "\r\n",
        "  mask_path = os.path.join(training_dir, \"Masks\", os.path.splitext(img)[0] + '.png') #take mask with the same name of the image\r\n",
        "  assert(os.path.exists(mask_path))\r\n",
        "  mask = Image.open(mask_path)\r\n",
        "\r\n",
        "  # RESIZE\r\n",
        "  image = image.resize(out_shape)\r\n",
        "\r\n",
        "  mask = mask.resize(out_shape)\r\n",
        "\r\n",
        "  #TO NUMPY ARRAY\r\n",
        "  image = np.array(image)\r\n",
        "  mask = np.array(mask)\r\n",
        "\r\n",
        "  #TRANFORM\r\n",
        "  img_y = img_data_gen.get_random_transform(out_shape, seed=SEED)\r\n",
        "  mask_t = mask_data_gen.get_random_transform(out_shape, seed=SEED)\r\n",
        "  image = img_data_gen.apply_transform(image, img_y)\r\n",
        "  mask = mask_data_gen.apply_transform(mask, mask_t)\r\n",
        "\r\n",
        "  #APPLY READ_RGB_MASK FUNCTION\r\n",
        "  mask = read_rgb_mask(mask)\r\n",
        "\r\n",
        "  #APPEND ALL IMAGES AND MASKS\r\n",
        "  img_arr.append(image)\r\n",
        "  mask_arr.append(mask)\r\n",
        "\r\n",
        "  \r\n",
        "    \r\n",
        "  #END FOR\r\n",
        "\r\n",
        "#DIVIDE TRAIN AND VALIDATION ARRAYS\r\n",
        "bound = math.floor(len(img_arr)*validation_split)\r\n",
        "train_img_array = img_arr[: bound]\r\n",
        "valid_img_array = img_arr[bound :]\r\n",
        "\r\n",
        "train_mask_array = mask_arr[: bound]\r\n",
        "valid_mask_array = mask_arr[bound :]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dom7qvLgwnmA"
      },
      "source": [
        "#CONVERT LIST TO NP ARRAYS\r\n",
        "train_img_array = np.array(train_img_array)\r\n",
        "train_mask_array = np.array(train_mask_array)\r\n",
        "valid_img_array = np.array(valid_img_array)\r\n",
        "valid_mask_array = np.array(valid_mask_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpu2_Xwnwsj9"
      },
      "source": [
        "#TEST IMAGES\r\n",
        "img_arr = []\r\n",
        "for crop_group in os.listdir(test_dir):\r\n",
        "  for crop_type in os.listdir(test_dir + crop_group):\r\n",
        "     for img in os.listdir(test_dir + crop_group + \"/\" + crop_type + \"/Images\"): \r\n",
        "        print(img)\r\n",
        "        #GET IMAGE\r\n",
        "        img_path = os.path.join(test_dir + crop_group + \"/\" + crop_type + \"/Images/\", img)\r\n",
        "        image = Image.open(img_path)\r\n",
        "\r\n",
        "        #RESIZE IMAGE AND MASK\r\n",
        "        image = image.resize(out_shape)\r\n",
        "        image = np.array(image)\r\n",
        "        \r\n",
        "        #APPEND TO A LIST\r\n",
        "        img_arr.append(image)\r\n",
        "  \r\n",
        "#LIST TO NP ARRAY\r\n",
        "test_img_array= np.array(img_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNi6ItR-wsbu"
      },
      "source": [
        "#VISUALIZE IMAGES AND MASKS\r\n",
        "fig=pyplot.figure(figsize=(8, 8))\r\n",
        "h = 3\r\n",
        "w = 2\r\n",
        "\r\n",
        "#MODIFY THESE PARAMETERS TO EXPLORE THE ARRAYS\r\n",
        "m = 0\r\n",
        "n = 0\r\n",
        "p = 0\r\n",
        "\r\n",
        "fig.add_subplot(h, w, 1)\r\n",
        "pyplot.imshow(train_img_array[m])\r\n",
        "fig.add_subplot(h, w, 2)\r\n",
        "pyplot.imshow(train_mask_array[m])\r\n",
        "\r\n",
        "fig.add_subplot(h, w, 3)\r\n",
        "pyplot.imshow(valid_img_array[n])\r\n",
        "fig.add_subplot(h, w, 4)\r\n",
        "pyplot.imshow(valid_mask_array[n])\r\n",
        "\r\n",
        "fig.add_subplot(h, w, 5)\r\n",
        "pyplot.imshow(test_img_array[p])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo3gpbwkwyj5"
      },
      "source": [
        "#CREATE DATASETS\r\n",
        "\r\n",
        "#SET BATCH SIZE\r\n",
        "bs= 8\r\n",
        "\r\n",
        "train_mask_array = tf.expand_dims(train_mask_array, -1)\r\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_img_array, train_mask_array))\r\n",
        "train_dataset = train_dataset.batch(bs)\r\n",
        "train_dataset = train_dataset.repeat()\r\n",
        "\r\n",
        "valid_mask_array = tf.expand_dims(valid_mask_array, -1)\r\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((valid_img_array, valid_mask_array))\r\n",
        "val_dataset = val_dataset.batch(bs)\r\n",
        "val_dataset = val_dataset.repeat()\r\n",
        "\r\n",
        "test_dataset = tf.data.Dataset.from_tensors(test_img_array)\r\n",
        "\r\n",
        "print(train_dataset)\r\n",
        "print(val_dataset)\r\n",
        "print(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLO5mxg0w1cr"
      },
      "source": [
        "#VISUALIZE TRAIN DATASET\r\n",
        "\r\n",
        "#VisualizeTrainSet\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "TrainIterator = iter(train_dataset)\r\n",
        "train_augmented_img, target = next(TrainIterator)\r\n",
        "train_augmented_img = np.array(train_augmented_img[0])\r\n",
        "train_augmented_img = train_augmented_img \r\n",
        "plt.imshow(np.uint8(train_augmented_img))\r\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmsdQvkSw4f0"
      },
      "source": [
        "#VISUALIZE VALID DATASET\r\n",
        "\r\n",
        "#VisualizeValidSet\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "ValidIterator = iter(val_dataset)\r\n",
        "valid_augmented_img, target = next(ValidIterator)\r\n",
        "valid_augmented_img = np.array(valid_augmented_img[0])\r\n",
        "valid_augmented_img = valid_augmented_img \r\n",
        "plt.imshow(np.uint8(valid_augmented_img))\r\n",
        "\r\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HApKV1iRw4WR"
      },
      "source": [
        "#VISUALIZE TESTDATASET\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "TestIterator = iter(test_dataset)\r\n",
        "test_augmented_img = next(TestIterator)\r\n",
        "test_augmented_img = np.array(test_augmented_img[2])\r\n",
        "test_augmented_img = test_augmented_img \r\n",
        "plt.imshow(np.uint8(test_augmented_img))\r\n",
        "\r\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIKZek_5w9Xb"
      },
      "source": [
        "def create_trivial_model( im_shape, depth, start_f, num_classes):\r\n",
        "\r\n",
        "    model = tf.keras.Sequential()\r\n",
        "    vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=im_shape)\r\n",
        "\r\n",
        "    for layer in vgg.layers:\r\n",
        "      layer.trainable = False\r\n",
        "\r\n",
        "    model.add(vgg)\r\n",
        "    \r\n",
        "    # Encoder\r\n",
        "    # -------\r\n",
        "    start_f = 256 #256\r\n",
        "        \r\n",
        "    # Decoder\r\n",
        "    # -------\r\n",
        "    for i in range(depth):\r\n",
        "        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\r\n",
        "        model.add(tf.keras.layers.Conv2D(filters=start_f,\r\n",
        "                                         kernel_size=(3, 3),\r\n",
        "                                         strides=(1, 1),\r\n",
        "                                         padding='same'))\r\n",
        "        model.add(tf.keras.layers.ReLU())\r\n",
        "\r\n",
        "        start_f = start_f // 2\r\n",
        "    \r\n",
        "    # Prediction Layer\r\n",
        "    # ----------------\r\n",
        "    model.add(tf.keras.layers.Conv2D(filters=num_classes,\r\n",
        "                                     kernel_size=(1, 1),\r\n",
        "                                     strides=(1, 1),\r\n",
        "                                     padding='same',\r\n",
        "                                     activation='softmax'))\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_pIJdd8xAjk"
      },
      "source": [
        "#CREATE THE TRIVIAL MODEL\r\n",
        "\r\n",
        "im_shape = (train_img_array.shape[1:])\r\n",
        "\r\n",
        "model = create_trivial_model(im_shape = im_shape,\r\n",
        "                    depth=5, \r\n",
        "                    start_f=8, \r\n",
        "                    num_classes=3)\r\n",
        "\r\n",
        "\r\n",
        "#VISUALIZE MODEL\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT4e1cMwxAaX"
      },
      "source": [
        "# Optimization params\r\n",
        "# -------------------\r\n",
        "\r\n",
        "# Loss\r\n",
        "# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\r\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy() \r\n",
        "# learning rate\r\n",
        "lr = 1e-3\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "# -------------------\r\n",
        "\r\n",
        "# Here we define the intersection over union for each class in the batch.\r\n",
        "# Then we compute the final iou as the mean over classes\r\n",
        "def meanIoU(y_true, y_pred):\r\n",
        "\r\n",
        "    per_class_iou = []\r\n",
        "\r\n",
        "    for i in range(1,3):\r\n",
        "      # Get prediction and target related to only a single class (i)\r\n",
        "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\r\n",
        "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\r\n",
        "      intersection = tf.reduce_sum(class_true * class_pred)\r\n",
        "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\r\n",
        "    \r\n",
        "      iou = (intersection + 1e-7) / (union + 1e-7)\r\n",
        "      per_class_iou.append(iou)\r\n",
        "\r\n",
        "    return tf.reduce_mean(per_class_iou)\r\n",
        "\r\n",
        "# Validation metrics\r\n",
        "# ------------------\r\n",
        "metrics = [meanIoU, 'accuracy']\r\n",
        "# ------------------\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dQlkrJqxImi"
      },
      "source": [
        "#CALLBACKS\r\n",
        "\r\n",
        "ckpt_dir = os.path.join(dataset_dir, \"checkpoints\")\r\n",
        "if (not os.path.exists(ckpt_dir)):\r\n",
        "  os.makedirs(ckpt_dir)# Model checkpoint\r\n",
        "\r\n",
        "tb_dir = os.path.join(dataset_dir, 'tb_logs')\r\n",
        "if not os.path.exists(tb_dir):\r\n",
        "    os.makedirs(tb_dir)\r\n",
        "\r\n",
        "# ----------------\r\n",
        "callbacks = []\r\n",
        "\r\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \r\n",
        "                                                   save_weights_only=True, restore_best_weights=True)  # False to save the model directly\r\n",
        "callbacks.append(ckpt_callback)\r\n",
        "\r\n",
        "# Visualize Learning on Tensorboard\r\n",
        "# ---------------------------------\r\n",
        "    \r\n",
        "# By default shows losses and metrics for both training and validation\r\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\r\n",
        "                                             profile_batch=0,\r\n",
        "                                             histogram_freq=0)  # if 1 shows weights histograms\r\n",
        "callbacks.append(tb_callback)\r\n",
        "\r\n",
        "# Early Stopping\r\n",
        "# --------------\r\n",
        "early_stop = True\r\n",
        "if early_stop:\r\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_meanIoU', restore_best_weights=True,patience=10)\r\n",
        "    callbacks.append(es_callback)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klA_KxTGxLdr"
      },
      "source": [
        "#COMPILE THE MODEL\r\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjFWqcyTxPtx"
      },
      "source": [
        "#TRAIN THE MODEL\r\n",
        "model.fit(x = train_dataset, \r\n",
        "          epochs = 30,\r\n",
        "          steps_per_epoch = len(train_img_array),\r\n",
        "          batch_size = bs,\r\n",
        "          validation_data = val_dataset,\r\n",
        "          validation_steps = len(valid_img_array),\r\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ26rzzHxPp8"
      },
      "source": [
        "#PREDICT WITH TEST_IMG_ARRAY\r\n",
        "\r\n",
        "pred = model.predict(x = test_img_array)\r\n",
        "pred.shape\r\n",
        "\r\n",
        "predictions = tf.argmax(pred,-1)\r\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPOqDC0-xTFj"
      },
      "source": [
        "#RLE ENCODE FUNCTION\r\n",
        "def rle_encode(img):\r\n",
        "    \r\n",
        "    #img: numpy array, 1 - foreground, 0 - background\r\n",
        "    #Returns run length as string formatted\r\n",
        "\r\n",
        "    pixels = img.flatten()\r\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\r\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\r\n",
        "    runs[1::2] -= runs[::2]\r\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znv4PwVTxpCW"
      },
      "source": [
        "#SUBMISSION\r\n",
        "submission_dict = {}\r\n",
        "i=0\r\n",
        "for crop_group in os.listdir(test_dir):\r\n",
        "  for crop_type in os.listdir(test_dir + crop_group):\r\n",
        "     for img in os.listdir(test_dir + crop_group + \"/\" + crop_type + \"/Images\"): \r\n",
        "        \r\n",
        "        #GET IMAGE\r\n",
        "        img_path = os.path.join(test_dir + crop_group + \"/\" + crop_type + \"/Images/\", img)\r\n",
        "        image = Image.open(img_path)\r\n",
        "        \r\n",
        "        #IMAGE NAME\r\n",
        "        image_name  = img[0:-4]\r\n",
        "        #IMAGE DIMENSIONS\r\n",
        "        image_shape = image.size\r\n",
        "        #TAKE IMAGE PREDICTION\r\n",
        "        image_prediction = predictions[i]\r\n",
        "        image_prediction = np.array(image_prediction)\r\n",
        "\r\n",
        "        #SWAP WIDTH AND HEIGHT FOR SKIMAGE RESIZE FUNCTION\r\n",
        "        true_w = image_shape[0]\r\n",
        "        true_h = image_shape[1]\r\n",
        "        true_image_shape = (true_h, true_w)\r\n",
        "\r\n",
        "        #RESHAPE TO ORIGINAL DIMENSIONS THE PREDICTION\r\n",
        "        image_prediction_reshaped = skimage.transform.resize(image_prediction, true_image_shape, order = 0)\r\n",
        "\r\n",
        "        #COMPUTE RLE ENCODING\r\n",
        "        #CROP RLE\r\n",
        "        rle_encoded_crop = rle_encode(image_prediction_reshaped == 1.6263032587282567e-19)\r\n",
        "        #WEED RLE\r\n",
        "        rle_encoded_weed = rle_encode(image_prediction_reshaped == 2.710505431213761e-19)\r\n",
        "\r\n",
        "        #CREAT THE SUBMISSION DICTIONARY\r\n",
        "        submission_dict[image_name] = {}\r\n",
        "        submission_dict[image_name]['shape'] = \"[\" + convertTuple(image_shape)[1:-1] + \"]\"\r\n",
        "        submission_dict[image_name]['team'] = crop_group\r\n",
        "        submission_dict[image_name]['crop'] = crop_type\r\n",
        "        submission_dict[image_name]['segmentation'] = {}\r\n",
        "\r\n",
        "        submission_dict[image_name]['segmentation']['crop'] = rle_encoded_crop\r\n",
        "        submission_dict[image_name]['segmentation']['weed'] = rle_encoded_weed\r\n",
        "\r\n",
        "        i = i + 1\r\n",
        "\r\n",
        "#CREATE JSON SUBMISION FILE\r\n",
        "delivery_folder = os.path.join(prediction_dir, \"output-15\")\r\n",
        "if (not os.path.exists(delivery_folder)):\r\n",
        "  os.makedirs(delivery_folder)\r\n",
        "\r\n",
        "with open(os.path.join(delivery_folder, \"submission.json\"), 'w') as f:\r\n",
        "  json.dump(submission_dict, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
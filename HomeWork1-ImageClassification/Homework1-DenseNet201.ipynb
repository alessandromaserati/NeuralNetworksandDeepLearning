{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet201-0.92888.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM9egqfjLCC7"
      },
      "source": [
        "# Homework 1 - Image Classification\n",
        "In this notebook, we have used Transfer Learning in order to achieve our best score on Kaggle. We used a **DenseNet201**, to which we added a **BatchNormalization** layer just before the output dense layer. We experimented also the insertion of the **ReduceLearningRateOnPlateau** callback function, which led us to better results once the learning started to stagnates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-8vO015y9zE"
      },
      "source": [
        "#import libraries\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bmnMTkYzJCi"
      },
      "source": [
        "#set random seed\n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)  \n",
        "cwd = os.getcwd()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGw32j8mzVSx"
      },
      "source": [
        "#Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baBfGRAYzcKk"
      },
      "source": [
        "#unzip challenge folders\n",
        "!unzip '/content/drive/My Drive/artificial-neural-networks-and-deep-learning-2020.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNtFLFNF0EKN"
      },
      "source": [
        "#dataset directories\n",
        "dataset_dir = os.path.join(cwd, 'MaskDataset')\n",
        "\n",
        "training_dir = os.path.join(dataset_dir, 'training')\n",
        "\n",
        "test_dir = os.path.join(dataset_dir, 'test')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an_ADQZC0Yf1"
      },
      "source": [
        "#ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#DataAugmentation\n",
        "\n",
        "apply_data_augmentation = True\n",
        "\n",
        "if apply_data_augmentation:\n",
        "  train_data_gen = ImageDataGenerator(rotation_range=30, \n",
        "                                      width_shift_range=30, \n",
        "                                      height_shift_range=30, \n",
        "                                      zoom_range=0.6, \n",
        "                                      horizontal_flip=True, \n",
        "                                      vertical_flip=True,\n",
        "                                      fill_mode='constant',\n",
        "                                      cval=0,\n",
        "                                      rescale=1/255.,\n",
        "                                      validation_split=0.2)\n",
        "else:\n",
        "  train_data_gen = ImageDataGenerator(rescale=1/255.,validation_split=0.2)\n",
        "\n",
        "valid_data_gen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "test_data_gen = ImageDataGenerator(rescale=1/255.)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZVVm6_r0yT7"
      },
      "source": [
        "#param. setting\n",
        "\n",
        "#BatchSize\n",
        "bs = 16 #bs = 32 affected negatively the performances of our net\n",
        "\n",
        "#ImageSizes for DenseNet201\n",
        "img_h = 224\n",
        "img_w = 224\n",
        "\n",
        "#NumClasses\n",
        "num_classes = 3"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tru0uds714Fr"
      },
      "source": [
        "#DataGenerators\n",
        "with open('MaskDataset/train_gt.json') as f:\n",
        "  dic = json.load(f)\n",
        "dataframe = pd.DataFrame(dic.items())\n",
        "dataframe.rename(columns = {0:'filename', 1:'class'}, inplace = True)\n",
        "dataframe[\"class\"] = dataframe[\"class\"].astype(str)\n",
        "\n",
        "\n",
        "train_gen = train_data_gen.flow_from_dataframe(dataframe,\n",
        "                                               training_dir,\n",
        "                                               batch_size=bs,\n",
        "                                               target_size=(img_h, img_w),\n",
        "                                               class_mode='categorical',\n",
        "                                               shuffle=True,\n",
        "                                               seed=SEED,\n",
        "                                               subset='training')\n",
        "\n",
        "valid_gen = train_data_gen.flow_from_dataframe(dataframe,\n",
        "                                               training_dir,\n",
        "                                               batch_size=bs,\n",
        "                                               target_size=(img_h, img_w),\n",
        "                                               class_mode='categorical',\n",
        "                                               shuffle=True,\n",
        "                                               seed=SEED,\n",
        "                                               subset='validation')\n",
        "\n",
        "test_gen = test_data_gen.flow_from_directory(dataset_dir, classes=['test'], batch_size=bs, class_mode=None,shuffle=False, seed=SEED)\n",
        "valid_gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su5E94Kv2N9p"
      },
      "source": [
        "#Datasets\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen, output_types=(tf.float32, tf.float32), output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, output_types=(tf.float32, tf.float32), output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
        "valid_dataset = valid_dataset.repeat()\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(lambda: test_gen, output_types=(tf.float32, tf.float32), output_shapes=([None, img_h, img_w, 3], [None, num_classes]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgi_EoOX2c0j"
      },
      "source": [
        "#VisualizeTrainSet\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "TrainIterator = iter(train_dataset)\n",
        "train_augmented_img, target = next(TrainIterator)\n",
        "train_augmented_img = np.array(train_augmented_img[0])\n",
        "train_augmented_img = train_augmented_img * 255\n",
        "plt.imshow(np.uint8(train_augmented_img))\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLY3EnD92hFo"
      },
      "source": [
        "#VisualizeValidSet\n",
        "import matplotlib.pyplot as plt\n",
        "ValidIterator = iter(valid_dataset)\n",
        "valid_augmented_img, target = next(ValidIterator)\n",
        "valid_augmented_img = np.array(valid_augmented_img[1])\n",
        "valid_augmented_img = valid_augmented_img*255\n",
        "plt.imshow(np.uint8(valid_augmented_img))\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW6wAFON3jB6"
      },
      "source": [
        "#NeuralNetwork\n",
        "denseNet201 = tf.keras.applications.DenseNet201(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(denseNet201)\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7oL1VbA9ETU"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4MCpXpL5Tsj"
      },
      "source": [
        "#Loss, LR,and Metrics\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "lr = 1e-4 #initially we tried lr = 1e-5, but with RLROP function, 1e-4 is better (faster but equally precise)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "metrics = ['accuracy']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSl1A-kT5oBl"
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bXSge_B6brb"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "cwd = os.getcwd()\n",
        "\n",
        "exps_dir = os.path.join('/content/drive/My Drive/Keras3/', 'classification_experiments')\n",
        "if not os.path.exists(exps_dir):\n",
        "    os.makedirs(exps_dir)\n",
        "\n",
        "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "model_name = 'CNN'\n",
        "\n",
        "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "if not os.path.exists(exp_dir):\n",
        "    os.makedirs(exp_dir)\n",
        "    \n",
        "callbacks = []\n",
        "\n",
        "# Model checkpoint\n",
        "\n",
        "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "    os.makedirs(ckpt_dir)\n",
        "\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
        "                                                   save_weights_only=True)  # False to save the model directly\n",
        "callbacks.append(ckpt_callback)\n",
        "\n",
        "# Visualize Learning on Tensorboard\n",
        "\n",
        "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "if not os.path.exists(tb_dir):\n",
        "    os.makedirs(tb_dir)\n",
        "    \n",
        "# By default shows losses and metrics for both training and validation\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                             profile_batch=0,\n",
        "                                             histogram_freq=1)  # if 1 shows weights histograms\n",
        "callbacks.append(tb_callback)\n",
        "\n",
        "# Early Stopping\n",
        "\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    callbacks.append(es_callback)\n",
        "\n",
        "#ReduceLRonPlateau\n",
        "#This function led us to better results\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor= 'val_loss', factor = 0.1, patience=5, verbose = 1, min_lr = 1e-5)\n",
        "\n",
        "callbacks.append(reduce_lr)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2ROx3wP63A7"
      },
      "source": [
        "#Train the Model\n",
        "model.fit(x=train_dataset, epochs=100, steps_per_epoch=len(train_gen), validation_data=valid_dataset, validation_steps=len(valid_gen), callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh8iWWJW7jdg"
      },
      "source": [
        "#Test Prediction\n",
        "STEP_SIZE_TEST = len(test_gen)\n",
        "pred=model.predict(test_gen,steps=STEP_SIZE_TEST,verbose=1)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for i in pred:\n",
        "    if i[0]>i[1] and i[0]> i[2]:\n",
        "        predictions.append('0')\n",
        "    elif i[1] > i[2]:\n",
        "        predictions.append('1')\n",
        "    else:\n",
        "        predictions.append('2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qsENcf87rLT"
      },
      "source": [
        "#Create the results\n",
        "filenames=test_gen.filenames\n",
        "for i in range(0,len(filenames)):\n",
        "  filenames[i] = filenames[i][5:]\n",
        "\n",
        "results=pd.DataFrame({\"Id\":filenames,\n",
        "                      \"Category\":predictions})"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIhpXFlxnkyC"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE1kZSGo7uYt"
      },
      "source": [
        "#Create the csv file\n",
        "results.to_csv('/content/drive/My Drive/Keras3/out20.csv', index=False) "
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}